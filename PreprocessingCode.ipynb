{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a0102ce",
   "metadata": {},
   "source": [
    "## 1. Importing necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings as wrn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93b7928",
   "metadata": {},
   "source": [
    "## 2. Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Frank\\OneDrive\\Documentos\\ITRI 616 Semester Project\\diabetic_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1bce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the last few rows of the dataframe\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f34b2",
   "metadata": {},
   "source": [
    "## 3. Checking the balance of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d26a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18437489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8983919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for null values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2228d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks the percentage of null values in each column\n",
    "df.isnull().sum()//df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85598dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the duplicate values in the dataset\n",
    "df .duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9bb956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying the garbage values in the dataset\n",
    "for iteration in df.select_dtypes(include=['object']).columns:\n",
    "    print(df[iteration].value_counts())\n",
    "    print(\"*\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc04dd00",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provides the summary statistics of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include =\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afcd005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the histogram to understand the distribution of the dataset\n",
    "for i in df.select_dtypes(include = \"number\").columns:\n",
    "    sns.histplot(data=df,x=i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f083c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the boxplot to identify the outliers in the dataset\n",
    "for i in df.select_dtypes(include = \"number\").columns:\n",
    "    sns.boxplot(data=df,x=i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the scatterplot to understand the relationship between the features\n",
    "for i in df.select_dtypes(include = \"number\").columns:\n",
    "    for j in df.select_dtypes(include = \"number\").columns:\n",
    "        if i != j:\n",
    "            sns.scatterplot(data=df,x=i,y=j)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04640ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the correlation with heatmap to interprer the relation and multicolliniarity\n",
    "s=df.select_dtypes(include=\"number\").corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(15,15))\n",
    "sns.heatmap(s,annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcc0ed8",
   "metadata": {},
   "source": [
    "## 5. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbce692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wrn.filterwarnings(\"ignore\")\n",
    "df['race'].fillna('Unknown', inplace=True)\n",
    "df['payer_code'].fillna('Self-Pay', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a565de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['race'] = df['race'].replace('?', 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A1Cresult\"] = df[\"A1Cresult\"].fillna(\"NotTested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"max_glu_serum\"] = df[\"max_glu_serum\"].fillna(\"NotTested\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da460f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weight_recorded'] = df['weight'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbe125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diag_1'].fillna('Unknown', inplace=True)\n",
    "df['diag_2'].fillna('Unknown', inplace=True)\n",
    "df['diag_3'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae07d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in df.select_dtypes(include=['object']).columns:\n",
    "    print(df[iteration].value_counts())\n",
    "    print(\"*\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3419e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55530e9d",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a8123",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mapping = {\n",
    "    '[0-10)': 5,\n",
    "    '[10-20)': 15,\n",
    "    '[20-30)': 25,\n",
    "    '[30-40)': 35,\n",
    "    '[40-50)': 45,\n",
    "    '[50-60)': 55,\n",
    "    '[60-70)': 65,\n",
    "    '[70-80)': 75,\n",
    "    '[80-90)': 85,\n",
    "    '[90-100)': 95\n",
    "}\n",
    "df['age'] = df['age'].map(age_mapping)\n",
    "# Create a binary target variable for readmission within 30 days\n",
    "df['readmitted_30'] = df['readmitted'].apply(lambda x: 1 if x == '<30' else 0)\n",
    "\n",
    "# Create a binary target variable for any readmission (within 30 or >30 days)\n",
    "df['readmitted_any'] = df['readmitted'].apply(lambda x: 1 if x != 'NO' else 0)\n",
    "\n",
    "# Create feature for number of diagnoses (from diag_1, diag_2, diag_3)\n",
    "df['num_diagnoses'] = df[['diag_1', 'diag_2', 'diag_3']].notna().sum(axis=1)\n",
    "\n",
    "# Create feature for medication changes\n",
    "df['med_change'] = df['change'].apply(lambda x: 1 if x == 'Ch' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc6e42",
   "metadata": {},
   "source": [
    "## 7. Outliers Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fe0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decide whether to do outliers treatment or not\n",
    "def wisker(col):\n",
    "   q1,q3=np.percentile(col,[25,75])\n",
    "   iqr = q3 - q1\n",
    "   lower_bound = q1 - 1.5 * iqr\n",
    "   upper_bound = q3 + 1.5 * iqr\n",
    "   return lower_bound, upper_bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4d69c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['patient_nbr','discharge_disposition_id','num_lab_procedures','num_medications','number_outpatient', 'number_emergency', 'number_inpatient']:\n",
    "    lower_bound, upper_bound = wisker(df[i])\n",
    "    df[i] = np.where(df[i] < lower_bound, lower_bound, df[i])\n",
    "    df[i] = np.where(df[i] > upper_bound, upper_bound, df[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50713f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a5f36",
   "metadata": {},
   "source": [
    "## 8. Encoding categorical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738eddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dummies for categorical variables\n",
    "# One-hot encode gender and race\n",
    "df = pd.get_dummies(df, columns=['gender', 'race'], drop_first=True)\n",
    "\n",
    "# Label encode other categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_cols = ['admission_type_id', 'discharge_disposition_id', \n",
    "                   'admission_source_id', 'A1Cresult', 'max_glu_serum']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Convert medication columns to binary (Yes=1, No=0)\n",
    "medication_cols = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "                  'glimepiride', 'acetohexamide', 'glipizide', 'glyburide',\n",
    "                  'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose',\n",
    "                  'miglitol', 'troglitazone', 'tolazamide', 'examide',\n",
    "                  'citoglipton', 'insulin', 'glyburide-metformin',\n",
    "                  'glipizide-metformin', 'glimepiride-pioglitazone',\n",
    "                  'metformin-rosiglitazone', 'metformin-pioglitazone']\n",
    "\n",
    "for col in medication_cols:\n",
    "    df[col] = df[col].map({'No': 0, 'Steady': 1, 'Up': 1, 'Down': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84dacf6",
   "metadata": {},
   "source": [
    "## 9. Handling Diagnosis Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e7fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group diagnosis codes into categories (ICD-9 codes)\n",
    "def group_diagnosis(code):\n",
    "    if pd.isna(code) or code == '?':\n",
    "        return 0\n",
    "    try:\n",
    "        code = float(code)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    if code >= 390 and code <= 459 or code == 785:\n",
    "        return 1  # Circulatory\n",
    "    elif code >= 460 and code <= 519 or code == 786:\n",
    "        return 2  # Respiratory\n",
    "    elif code >= 520 and code <= 579 or code == 787:\n",
    "        return 3  # Digestive\n",
    "    elif code >= 250 and code < 251:\n",
    "        return 4  # Diabetes\n",
    "    elif code >= 800 and code <= 999:\n",
    "        return 5  # Injury\n",
    "    elif code >= 710 and code <= 739:\n",
    "        return 6  # Musculoskeletal\n",
    "    elif code >= 580 and code <= 629 or code == 788:\n",
    "        return 7  # Genitourinary\n",
    "    elif code >= 140 and code <= 239:\n",
    "        return 8  # Neoplasms\n",
    "    else:\n",
    "        return 0  # Other\n",
    "\n",
    "for diag_col in ['diag_1', 'diag_2', 'diag_3']:\n",
    "    df[diag_col+'_group'] = df[diag_col].apply(group_diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b7249",
   "metadata": {},
   "source": [
    "## 10. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4119db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale numerical features\n",
    "numerical_features = ['time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
    "                     'num_medications', 'number_diagnoses', 'number_outpatient',\n",
    "                     'number_emergency', 'number_inpatient', 'age']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01733f",
   "metadata": {},
   "source": [
    "## 11. Final Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254d7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original columns we've transformed\n",
    "columns_to_drop = ['encounter_id', 'patient_nbr', 'readmitted', 'diag_1', 'diag_2', 'diag_3', 'change']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Drop diabetesMed since it's highly correlated with our target (most patients have diabetes)\n",
    "df.drop(columns=['diabetesMed'], inplace=True)\n",
    "\n",
    "# Check for class imbalance in target variables\n",
    "print(df['readmitted_30'].value_counts())\n",
    "print(df['readmitted_any'].value_counts())\n",
    "\n",
    "# If severe imbalance exists, we might apply SMOTE later during modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dd6f02",
   "metadata": {},
   "source": [
    "## 12. Save the preprocessed dataset for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b86565",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('diabetic_data_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
